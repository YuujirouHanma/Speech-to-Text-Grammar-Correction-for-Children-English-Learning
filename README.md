# ğŸ¤ Speech-to-Text & Grammar Correction for Children English Learning

## ğŸ“Œ Overview

This project implements an **AI-based monitoring system for childrenâ€™s English language learning** by integrating:

* Speech-to-Text (STT)
* Automated Grammar Correction (GEC)
* Transformer-based NLP models

The system converts children's speech into text and automatically corrects grammatical errors to provide **real-time learning feedback**.

---

## ğŸ¯ Objectives

* Build an integrated pipeline for **speech transcription + grammar correction**
* Compare **Custom Seq2Seq Transformer vs Pretrained T5**
* Evaluate performance using **BLEU, METEOR, ROUGE, Exact Match**
* Support **real-time English learning monitoring for children**

---

## ğŸ§  System Architecture

Pipeline:

```
Audio Input â†’ Speech-to-Text â†’ Text Preprocessing â†’ Grammar Correction â†’ Output Display
```

Main Components:

* Audio Recording / Upload
* STT Engine (Whisper / Gemini / Deepgram)
* Grammar Correction Model (T5 / Custom Seq2Seq)
* Gradio Web Interface

---

## ğŸš€ Features

âœ… Real-time speech transcription
âœ… Automatic grammar correction
âœ… Multi STT Engine support
âœ… Custom Transformer model implementation
âœ… Pretrained T5 Fine-tuning
âœ… Interactive Web UI (Gradio)
âœ… Multi-scenario training pipeline
âœ… Educational feedback potential

---

## ğŸ›  Tech Stack

### AI / NLP

* T5 (Text-to-Text Transfer Transformer)
* Custom Seq2Seq Transformer (PyTorch)
* SentencePiece Tokenizer

### Speech AI

* Whisper (Local STT)
* Google Gemini Flash 2.0 / 1.5
* Deepgram Nova-2

### ML / Data

* Scikit-learn
* LightGBM
* NL-Augmenter
* ERRANT (Error Annotation Toolkit)

### Framework & Tools

* PyTorch
* HuggingFace Transformers
* HappyTransformer
* Gradio

---

## ğŸ“Š Dataset

| Dataset                    | Source      | Usage                        |
| -------------------------- | ----------- | ---------------------------- |
| Grammar Correction Dataset | Kaggle      | Supervised training          |
| JFLEG                      | HuggingFace | Fluency correction benchmark |

---

## ğŸ§ª Experiment Scenarios

1ï¸âƒ£ Auto Pseudo Labeling (ERRANT)
2ï¸âƒ£ Pseudo Labeling + Augmentation
3ï¸âƒ£ Pure Supervised Training
4ï¸âƒ£ Direct Training on JFLEG
5ï¸âƒ£ Ensemble Pseudo Labeling + Heavy Augmentation

---

## ğŸ“ˆ Evaluation Metrics

* BLEU
* METEOR
* ROUGE-1 / ROUGE-2 / ROUGE-L
* Exact Match
* Precision / Recall / F1 (Error Type Classification)

---

## ğŸ† Key Results

### Best Performance

Model: **T5 + Pseudo Labeling + Augmentation**

| Metric      | Score  |
| ----------- | ------ |
| BLEU        | 0.8567 |
| METEOR      | 0.9329 |
| ROUGE-L     | 0.9704 |
| Exact Match | 0.6800 |

ğŸ“Œ T5 consistently outperformed Custom Seq2Seq across all scenarios.

---

## ğŸ¤ Speech-to-Text Performance Insights

### Best Conditions

* Quiet environment â†’ Highest transcription accuracy

### Challenges

* Noise environment â†’ STT semantic errors propagate to GEC stage

### Best STT Overall

* Gemini Flash 2.0 (Balanced speed & accuracy)
* Whisper (Good local baseline)

---

## ğŸ’¡ Educational Impact

This system can:

* Help children practice English speaking
* Provide instant grammar feedback
* Support teachers in monitoring student progress
* Reduce manual correction workload

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourusername/your-repo-name.git
cd your-repo-name
pip install -r requirements.txt
```

---

## â–¶ Usage

Run Gradio interface:

```bash
python app.py
```

Then open browser â†’ Local Gradio URL

---

## ğŸ“‚ Project Structure (Example)

```
project/
â”‚
â”œ models/
â”œ data/
â”œ src/
â”œ notebooks/
â”œ saved_model/
â”‚
â”œ app.py
â”œ train.py
â”œ requirements.txt
â”” README.md
```

---

## ğŸ”¬ Future Work

* Fine-tune STT using children speech dataset
* Upgrade to larger LLM-based GEC models
* Add educational feedback explanation system
* Real classroom user testing

---

## ğŸ‘¨â€ğŸ’» Author

Your Name

---

